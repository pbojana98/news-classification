{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bojana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bojana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Bojana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Bojana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import nltk\n",
    "import sklearn\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date headline_category  \\\n",
       "0      20010102           unknown   \n",
       "1      20010102           unknown   \n",
       "2      20010102           unknown   \n",
       "3      20010102           unknown   \n",
       "4      20010102           unknown   \n",
       "\n",
       "                                       headline_text  \n",
       "0  Status quo will not be disturbed at Ayodhya; s...  \n",
       "1                Fissures in Hurriyat over Pak visit  \n",
       "2              America's unwanted heading for India?  \n",
       "3                 For bigwigs; it is destination Goa  \n",
       "4               Extra buses to clear tourist traffic  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('podaci.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_category</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment.hindi.bollywood</td>\n",
       "      <td>Raju Chacha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment.hindi.bollywood</td>\n",
       "      <td>'Devdas': Jinxed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india</td>\n",
       "      <td>Dudhwa tiger died of starvation; not poisoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city.bengaluru</td>\n",
       "      <td>Three in race for chief secy's post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>city.patna</td>\n",
       "      <td>Druggists' stir leads to shortage of medicines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               headline_category  \\\n",
       "0  entertainment.hindi.bollywood   \n",
       "1  entertainment.hindi.bollywood   \n",
       "2                          india   \n",
       "3                 city.bengaluru   \n",
       "4                     city.patna   \n",
       "\n",
       "                                    headline_text  \n",
       "0                                     Raju Chacha  \n",
       "1                               'Devdas': Jinxed?  \n",
       "2  Dudhwa tiger died of starvation; not poisoning  \n",
       "3             Three in race for chief secy's post  \n",
       "4  Druggists' stir leads to shortage of medicines  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iz DataFrame-a sam izbacila kolonu publish_date jer mi nije potrebna, kao i sve vrste u kojima je vrednost headline_category jednaka unknown ili removed.\n",
    "df = df.drop('publish_date', 1)\n",
    "df = df[(df['headline_category'] != 'unknown') & (df['headline_category'] != 'removed')].reset_index()\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zatim, cilj mi je da od kolone headline_category napravim novu kolonu 'category' tako sto elemente koji sadrze rec 'sports' iz te kolone ubacim u grupu 'sports' u koloni 'category',\n",
    "# elemente koji sadrze rec 'politics' ubacim u grupu 'politics', a svi ostali elementi te kolone spadaju u grupu others. \n",
    "\n",
    "conditions = [\n",
    "    (df['headline_category'].str.contains('sports')),\n",
    "    (df['headline_category'].str.contains('politics')),\n",
    "    ]\n",
    "choices = ['sports', 'politics']\n",
    "df['category'] = np.select(conditions, choices, default='others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kada sam napravila novu kolonu 'category', onda mogu da obrisem headline_category jer mi vise ne treba.\n",
    "df = df.drop('headline_category', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['others', 'sports', 'politics'], dtype=object)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kolonu 'category' postavljam kao target i uzimam njene jedinstvene vrednosti, samo da proverim da li je to ono sto mi treba.\n",
    "target_category = df['category'].unique()\n",
    "target_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raju Chacha</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Devdas': Jinxed?</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dudhwa tiger died of starvation; not poisoning</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three in race for chief secy's post</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Druggists' stir leads to shortage of medicines</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    headline_text category  categoryId\n",
       "0                                     Raju Chacha   others           0\n",
       "1                               'Devdas': Jinxed?   others           0\n",
       "2  Dudhwa tiger died of starvation; not poisoning   others           0\n",
       "3             Three in race for chief secy's post   others           0\n",
       "4  Druggists' stir leads to shortage of medicines   others           0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kako mi nije pogodno da radim sa stringovima, onda dodajem kolonu categoryId u kojoj mi je others =0 , sports = 1, politics = 2.\n",
    "df['categoryId'] = df['category'].factorize()[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  categoryId\n",
       "0    others           0\n",
       "1    sports           1\n",
       "2  politics           2"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category = df[[\"category\",\"categoryId\"]].drop_duplicates().sort_values('categoryId').reset_index().drop('index', 1)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dolazim do dela kada zelim da sredim podatke iz dataframe-a, pa to radim uz pomoc sledece funkcije.\n",
    "\n",
    "def preprocess_df(train_text):\n",
    "       \n",
    "    #prvo transformisem tekst u listu reci, i pritom ignorisem znakove interpunkcije\n",
    "    train_text= str(train_text)\n",
    "    tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=\" \")\n",
    "        \n",
    "    #izbacujem reci kao sto su: the, in, on, at.. jer mi one ne menjaju mnogo znacenje recenice, a veoma su ceste u tekstu. \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n",
    "     \n",
    "    #zatim ponovo spajam reci u recenice\n",
    "    stopwordremove_text = ' '.join(stopwordremove)\n",
    "        \n",
    "    #iz tih recenica zelim da uklonim brojeve, jer mi oni ne znace.\n",
    "    numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n",
    "       \n",
    "    #dalje koristim PorterStemmer, koji ostavlja samo koren reci, a lemmatizer reci koje imaju isti koren posmatra kao jedno. \n",
    "    stemmer= PorterStemmer()\n",
    "\n",
    "    stem_input=nltk.word_tokenize(numberremove_text)\n",
    "    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n",
    "        \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def get_wordnet_pos(word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    lem_input = nltk.word_tokenize(stem_text)\n",
    "    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n",
    "        \n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others      3077517\n",
       "sports       130535\n",
       "politics       1620\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame je dosta veliki, zato cu uzeti samo deo podataka. Od others i sports cu izdvojiti po 1000, dok cu za politics da ostavim svih 1620.\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = df[df.category == 'others']\n",
    "df.drop(df[df.category == 'others'].index, inplace=True)\n",
    "sports = df[df.category == 'sports']\n",
    "df.drop(df[df.category == 'sports'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acche din kidhar hain; asks PIL against PM and...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Call to widen 'health tax' net</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hike VAT on cigarettes: Harsh Vardhan</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maharashtra onion politics may bring tears to ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Budget 2014: Opposition flags price rise to di...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>Aston Villa see future business in India</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>Benitez praises Liverpool spirit</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>We are in heaven now; says Dudek</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>Safin; Sharapova advance</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>Federer eases past Moya into last 8</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          headline_text  category  categoryId\n",
       "0     Acche din kidhar hain; asks PIL against PM and...  politics           2\n",
       "1                        Call to widen 'health tax' net  politics           2\n",
       "2                 Hike VAT on cigarettes: Harsh Vardhan  politics           2\n",
       "3     Maharashtra onion politics may bring tears to ...  politics           2\n",
       "4     Budget 2014: Opposition flags price rise to di...  politics           2\n",
       "...                                                 ...       ...         ...\n",
       "3615           Aston Villa see future business in India    sports           1\n",
       "3616                   Benitez praises Liverpool spirit    sports           1\n",
       "3617                   We are in heaven now; says Dudek    sports           1\n",
       "3618                           Safin; Sharapova advance    sports           1\n",
       "3619                Federer eases past Moya into last 8    sports           1\n",
       "\n",
       "[3620 rows x 3 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df, others.head(1000), sports.head(1000)], ignore_index=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  acch din kidhar hain ask pil pm bjp\n",
       "1                         call widen 'health tax ' net\n",
       "2                      hike vat cigarett harsh vardhan\n",
       "3    maharashtra onion polit may bring tear modi go...\n",
       "4    budget opposit flag price rise disrupt day par...\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['headline_text'] = df_final['headline_text'].apply(preprocess_df)\n",
    "text = df_final['headline_text']\n",
    "category = df_final['category']\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delim na train i test. Zatim pravim KNN, Naive Bayes i Logistic Regression, pa racunam accuracy za njih.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text,category, test_size = 0.2, random_state = 60,shuffle=True, stratify=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Test Accuracy Score  : 0.787292817679558 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = Pipeline([('tfidf', TfidfVectorizer()), ('clf', KNeighborsClassifier(n_neighbors = 3))])\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "test_predict = knn.predict(X_test)\n",
    "\n",
    "test_accuracy =(accuracy_score(test_predict, Y_test))\n",
    "\n",
    "print(\"KNN Test Accuracy Score  : {} \".format(test_accuracy ))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test Accuracy Score  : 0.7886740331491713 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bayes = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "bayes.fit(X_train,Y_train)\n",
    "\n",
    "test_predict = bayes.predict(X_test)\n",
    "\n",
    "test_accuracy =(accuracy_score(test_predict, Y_test))\n",
    "\n",
    "print(\"Naive Bayes Test Accuracy Score  : {} \".format(test_accuracy ))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy Score  : 0.8798342541436464 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LogisticRegression(random_state=0)),])\n",
    "regression.fit(X_train,Y_train)\n",
    "\n",
    "test_predict = regression.predict(X_test)\n",
    "\n",
    "test_accuracy =(accuracy_score(test_predict, Y_test))\n",
    "\n",
    "print(\"Logistic Regression Test Accuracy Score  : {} \".format(test_accuracy ))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__solver</th>\n",
       "      <th>param_tfidf__norm</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.472260</td>\n",
       "      <td>0.072944</td>\n",
       "      <td>0.020810</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf__solver': 'lbfgs', 'tfidf__norm': 'l2'}</td>\n",
       "      <td>0.856897</td>\n",
       "      <td>0.873921</td>\n",
       "      <td>0.851468</td>\n",
       "      <td>0.841105</td>\n",
       "      <td>0.849741</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.280020</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'clf__solver': 'lbfgs', 'tfidf__norm': 'l1'}</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.708117</td>\n",
       "      <td>0.715026</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>0.723408</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108308</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.013168</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'clf__solver': 'saga', 'tfidf__norm': 'l2'}</td>\n",
       "      <td>0.856897</td>\n",
       "      <td>0.873921</td>\n",
       "      <td>0.851468</td>\n",
       "      <td>0.841105</td>\n",
       "      <td>0.849741</td>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093445</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'clf__solver': 'saga', 'tfidf__norm': 'l1'}</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.742660</td>\n",
       "      <td>0.708117</td>\n",
       "      <td>0.715026</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>0.724099</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.472260      0.072944         0.020810        0.006403   \n",
       "1       0.280020      0.014016         0.014644        0.003765   \n",
       "2       0.108308      0.022439         0.013168        0.004148   \n",
       "3       0.093445      0.010912         0.006044        0.005826   \n",
       "\n",
       "  param_clf__solver param_tfidf__norm  \\\n",
       "0             lbfgs                l2   \n",
       "1             lbfgs                l1   \n",
       "2              saga                l2   \n",
       "3              saga                l1   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0  {'clf__solver': 'lbfgs', 'tfidf__norm': 'l2'}           0.856897   \n",
       "1  {'clf__solver': 'lbfgs', 'tfidf__norm': 'l1'}           0.734483   \n",
       "2   {'clf__solver': 'saga', 'tfidf__norm': 'l2'}           0.856897   \n",
       "3   {'clf__solver': 'saga', 'tfidf__norm': 'l1'}           0.734483   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.873921           0.851468           0.841105           0.849741   \n",
       "1           0.740933           0.708117           0.715026           0.718480   \n",
       "2           0.873921           0.851468           0.841105           0.849741   \n",
       "3           0.742660           0.708117           0.715026           0.720207   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.854626        0.010900                1  \n",
       "1         0.723408        0.012313                4  \n",
       "2         0.854626        0.010900                1  \n",
       "3         0.724099        0.012690                3  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Najbolji accuracy dobijam za Logistic Regression. Desava mi se da kada menjam parametre, izbacuje mi gresku jer nemam dovoljno memorije.\n",
    "#Stoga, ostavila sam samo dva parametra da se menjaju, ostali su zakomentarisani.\n",
    "grid_params = {\n",
    "    #'tfidf__lowercase': [True, False],\n",
    "    #'tfidf__binary': [True, False],\n",
    "    #'tfidf__max_features': [None, 100000, 10000],\n",
    "    'tfidf__norm': ['l2', 'l1'],\n",
    "    #'tfidf__stop_words': [None, stopwords],\n",
    "    #'clf__C': [1.0, 0.1, 0.01],\n",
    "    #'clf__fit_intercept': [True, False],\n",
    "    #'clf__penalty': ['l2', 'l1'],\n",
    "    'clf__solver': ['lbfgs','saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = regression, param_grid=grid_params, scoring='accuracy')\n",
    "grid_search.fit(X_train, Y_train)\n",
    "score = pd.DataFrame(grid_search.cv_results_)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ea6174109c7db0d0f23544782bd685f867a961ccec7b1d0b1aca314793d1f6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
